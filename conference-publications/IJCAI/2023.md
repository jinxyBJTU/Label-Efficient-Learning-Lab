# [Publications in IJCAI 2023](https://www.ijcai.org/proceedings/2023/)

 - [Graph Self-supervised Learning](#graph-self-supervised-learning)
 - [General Contrastive Learning](#general-contrastive-learning)
 - [Weakly-supervised Learning](#weakly-supervised-learning)
 - [Label Noise Learning](#label-noise-learning)

## Graph Self-supervised Learning
### Multi-Scale Subgraph Contrastive Learning
 - [[paper](https://www.ijcai.org/proceedings/2023/0246.pdf)]
 - [code暂无]
 - 图级对比学习旨在通过对比两个增强的图来学习每个图的表示，已经引起了相当大的关注。以往的研究通常简单地假设一个图及其增强图为正对，其他情况为负对。然而，众所周知，图结构总是复杂且多尺度的，这引发了一个根本性问题：在图增强之后，先前的假设是否仍然成立？通过实验分析，我们发现增强图结构的语义信息可能与原始图结构不一致，而两个增强图是否为正对或负对与多尺度结构密切相关。基于这一发现，我们提出了一种多尺度子图对比学习方法，能够表征细粒度的语义信息。具体而言，我们基于子图采样在不同尺度上生成全局和局部视图，并根据它们的语义关联构建多个对比关系，以提供更丰富的自监督信号。在八个图分类的真实数据集上进行的大量实验和参数分析充分证明了所提方法的有效性。
   
### CSGCL: Community-Strength-Enhanced Graph Contrastive Learning
- [[paper](https://www.ijcai.org/proceedings/2023/0229.pdf)]
- [[code](https://github.com/HanChen-HUST/CSGCL)]
- 图对比学习（Graph Contrastive Learning，GCL）是一种有效的自监督学习方法，可用于以自我监督的方式学习通用的图表示，并在近年来迅速发展。然而，大多数先前的图对比学习方法并未充分探索社区语义。试图利用社区信息的研究将它们视为对图具有相同影响力，导致额外的表示偏差。为了解决这个问题，我们定义了“社区强度”来衡量社区之间影响力的差异。在此前提下，我们提出了一种增强社区强度的图对比学习（Community-Strength-enhanced Graph Contrastive Learning，CSGCL）框架，以在学习过程中保留社区强度。首先，我们提出了两种新颖的图增强方法，分别是Communal Attribute Voting（CAV）和Communal Edge Dropping（CED），其中节点属性和边的扰动是根据社区强度进行引导的。其次，我们提出了一种动态的“联合”对比学习方案，其中社区强度被用于逐渐微调对比目标。我们在三个下游任务上报告了大量实验结果：节点分类、节点聚类和链接预测。CSGCL相对于其他GCL方法实现了最先进的性能，验证了社区强度为图表示带来了有效性和普适性。

### Violin: Virtual Overbridge Linking for Enhancing Semi-supervised Learning on Graphs with Limited Labels
- [[paper](https://www.ijcai.org/proceedings/2023/0495.pdf)]
- [code暂无]
- 图神经网络（Graph Neural Networks，GNNs）是一类在图半监督学习中表现出潜力的工具。然而，在训练过程中，大多数现有的GNNs往往严重依赖大量标记数据，而在现实场景中，这种数据往往十分稀缺。未标记数据中蕴含的有用信息通常被充分利用，这限制了GNNs的表示能力。为了解决这些问题，我们提出了Virtual Overbridge Linking（Violin），这是一个通用框架，用于增强常见GNNs的学习能力。通过学习在估计为语义一致的两个节点之间添加虚拟过桥，可以将标记和未标记数据相关联。在训练过程中，监督信息可以得到充分利用，同时诱导模型从未标记数据中学习。即使未标记节点之间相隔较远，从未标记节点中提取的具有区分性的关系模式也可以与其他节点共享。受最近数据增强技术的启发，我们还将Violin与一致性正则化训练相结合。这样的方案可以产生具有更好鲁棒性的节点表示，从而显著增强了GNN。Violin可以轻松地扩展到各种GNNs，而不引入额外的可学习参数。在六个数据集上的广泛实验表明，我们的方法在低标签率情景下是有效且鲁棒的，Violin可以使一些GNNs的节点分类性能提高超过10%。

### Not Only Pairwise Relationships: Fine-Grained Relational Modeling for Multivariate Time Series Forecasting
- [[paper](https://www.ijcai.org/proceedings/2023/0491.pdf)]
- [code暂无]
- 最近，基于图的方法在多变量时间序列建模和预测中取得了显著成功，因为它们能够处理时间序列变量之间的关系。然而，在大多数现有的工作中，只考虑了成对关系。它们忽略了超过成对关系的其他关系以及在实际场景中可能存在的不同类别，这导致了对多变量时间序列预测的关系学习不够全面。在本文中，我们提出了一种基于关系建模的方法ReMo，以促进多变量时间序列数据之间的细粒度关系学习。首先，通过将时间序列变量和复杂关系视为节点和超边，我们从数据中提取多视图超图，以捕捉超过成对关系。其次，我们设计了一种新颖的超图消息传递策略，通过推断关系的潜在类别并进一步区分它们对时间序列变量的影响，来描述节点和超边。通过将这两个模块整合到时间序列预测框架中，ReMo有效地提高了多变量时间序列预测的性能。对来自不同领域的七个常用数据集的实验结果证明了我们模型的优越性。

### Forecasting Soil Moisture Using Domain Inspired Temporal Graph Convolution Neural Networks To Guide Sustainable Crop Management
- [[paper](https://www.ijcai.org/proceedings/2023/0654.pdf)]
- [code暂无]
- 由于气候变化、人口增长和水资源匮乏，农业面临前所未有的挑战。这些挑战突显了需要有效利用资源来优化作物生产的需求。传统的预测水文响应特征（如土壤湿度）的技术依赖于基于物理和经验的水文模型，这些模型需要大量的时间和领域专业知识。借鉴传统水文建模的灵感，构建了一种新颖的时间图卷积神经网络。这涉及根据它们的时间变化的水文特性对单元进行分组，基于动态时间规整使用相似性构建每个群集的图拓扑，并利用图卷积和门控循环神经网络来预测土壤湿度。该方法已经在美国东北部跨越40年的田间规模时间序列数据上进行了训练、验证和测试。结果显示，利用基于领域启发的聚类与时间序列图神经网络预测土壤湿度比现有模型更有效。

## General Contrastive Learning
 - [Part Aware Contrastive Learning for Self-Supervised Action Recognition](https://www.ijcai.org/proceedings/2023/0095.pdf)
 - [CSGCL: Community-Strength-Enhanced Graph Contrastive Learning](https://www.ijcai.org/proceedings/2023/0229.pdf)
 - [Multi-Scale Subgraph Contrastive Learning](https://www.ijcai.org/proceedings/2023/0246.pdf)
 - [Intent-aware Recommendation via Disentangled Graph Contrastive Learning](https://www.ijcai.org/proceedings/2023/0260.pdf)
 - [Contrastive Learning for Sign Language Recognition and Translation](https://www.ijcai.org/proceedings/2023/0085.pdf)
 - [ContrastMotion: Self-supervised Scene Motion Learning for Large-Scale LiDAR Point Clouds](https://www.ijcai.org/proceedings/2023/0103.pdf)
 - [Deep Unfolding Convolutional Dictionary Model for Multi-Contrast MRI Super-resolution and Reconstruction](https://www.ijcai.org/proceedings/2023/0112.pdf)
 - [CONGREGATE: Contrastive Graph Clustering in Curvature Spaces](https://www.ijcai.org/proceedings/2023/0255.pdf)
 - [A Logic-based Approach to Contrastive Explainability for Neurosymbolic Visual Question Answering](https://www.ijcai.org/proceedings/2023/0408.pdf)
 - [Contrastive Learning and Reward Smoothing for Deep Portfolio Management](https://www.ijcai.org/proceedings/2023/0441.pdf)
 - [MA2CL:Masked Attentive Contrastive Learning for Multi-Agent Reinforcement Learning](https://www.ijcai.org/proceedings/2023/0470.pdf)
 - [Contrastive Label Enhancement](https://www.ijcai.org/proceedings/2023/0484.pdf)
 - [CLE-ViT: Contrastive Learning Encoded Transformer for Ultra-Fine-Grained Visual Categorization](https://www.ijcai.org/proceedings/2023/0504.pdf)
 - [Multi-level Graph Contrastive Prototypical Clustering](https://www.ijcai.org/proceedings/2023/0513.pdf)
 - [Multi-view Contrastive Learning Hypergraph Neural Network for Drug-Microbe-Disease Association Prediction](https://www.ijcai.org/proceedings/2023/0537.pdf)
 - [A Diffusion Model with Contrastive Learning for ICU False Arrhythmia Alarm Reduction](https://www.ijcai.org/proceedings/2023/0546.pdf)
 - [GPMO: Gradient Perturbation-Based Contrastive Learning for Molecule Optimization](https://www.ijcai.org/proceedings/2023/0549.pdf)
 - [NerCo: A Contrastive Learning Based Two-Stage Chinese NER Method](https://www.ijcai.org/proceedings/2023/0587.pdf)
## Weakly-supervised Learning
 - [Hierarchical Semantic Contrast for Weakly Supervised Semantic Segmentation](https://www.ijcai.org/proceedings/2023/0171.pdf)
 - [Complete Instances Mining for Weakly Supervised Instance Segmentation](https://www.ijcai.org/proceedings/2023/0127.pdf)
 - [HOI-aware Adaptive Network for Weakly-supervised Action Segmentation](https://www.ijcai.org/proceedings/2023/0191.pdf)
 - [Addressing Weak Decision Boundaries in Image Classification by Leveraging Web Search and Generative Models](https://www.ijcai.org/proceedings/2023/0659.pdf)
 - [Unbiased Risk Estimator to Multi-Labeled Complementary Label Learning](https://www.ijcai.org/proceedings/2023/0415.pdf)
 - [Unreliable Partial Label Learning with Recursive Separation](https://www.ijcai.org/proceedings/2023/0468.pdf)
   
## Label Noise Learning
 - [MILD: Modeling the Instance Learning Dynamics for Learning with Noisy Labels](https://www.ijcai.org/proceedings/2023/0092.pdf)
 - [LION: Label Disambiguation for Semi-supervised Facial Expression Recognition with Progressive Negative Learning](https://www.ijcai.org/proceedings/2023/0078.pdf)
 - [Generalization Guarantees of Self-Training of Halfspaces under Label Noise Corruption](https://www.ijcai.org/proceedings/2023/0420.pdf)
 - [Stochastic Feature Averaging for Learning with Long-Tailed Noisy Labels](https://www.ijcai.org/proceedings/2023/0434.pdf)
 - [CTW: Confident Time-Warping for Time-Series Label-Noise Learning](https://www.ijcai.org/proceedings/2023/0450.pdf)
 - [FedNoRo: Towards Noise-Robust Federated Learning by Addressing Class Imbalance and Label Noise Heterogeneity](https://www.ijcai.org/proceedings/2023/0492.pdf)
 - [ProMix: Combating Label Noise via Maximizing Clean Sample Utility](https://www.ijcai.org/proceedings/2023/0494.pdf)
 - [A Noisy-Label-Learning Formulation for Immune Repertoire Classification and Disease-Associated Immune Receptor Sequence Identification](https://www.ijcai.org/proceedings/2023/0527.pdf)

