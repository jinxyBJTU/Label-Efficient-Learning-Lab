# [Publications in AAAI 2023](https://ojs.aaai.org/index.php/AAAI/issue/archive)
 - [Graph Self-supervised Learning](#graph-self-supervised-learning)
 - [General Contrastive Learning](#general-contrastive-learning)
 - [Weakly-supervised Learning](#weakly-supervised-learning)
 - [Label Noise Learning](#label-noise-learning)

## Graph Self-supervised Learning
### Spectral Feature Augmentation for Graph Contrastive Learning and Beyond
 - [[paper](https://arxiv.org/pdf/2212.01026.pdf)]
 - 虽然增强（如图边扰动、图像裁剪）提高了对比学习（CL）的效率，但特征级增强是另一种可行的、互补的、但尚未得到充分研究的策略。因此，我们提出了一种新颖的光谱特征论证方法，用于图（和图像）对比学习。为此，对于每个数据视图，我们都会估计每个特征图的低秩近似值，并将该近似值从图中减去，以获得其补充。这是通过本文提出的不完全幂迭代来实现的，这是一种非标准的幂迭代机制，它有两个有价值的副产品（只需一次或两次迭代）：(i) 它能部分平衡特征图的频谱，(ii) 它能将噪声注入重新平衡的特征图奇异值中（频谱增强）。对于两个视图，我们会对这些重新平衡的特征图进行对齐，因为这样改进的对齐步骤可以更多地关注两个视图矩阵中不占优势的奇异值，而频谱增强不会影响频谱角度的对齐（奇异向量不会受到扰动）。我们推导出了以下分析形式(i) 不完全幂迭代以捕捉其频谱平衡效应，以及 (ii) 由噪声隐式增强的奇异值方差。我们还证明，频谱增强提高了泛化边界。在图形/图像数据集上的实验表明，我们的频谱特征增强方法优于基线方法，而且与其他增强策略互补，并与各种对比损失兼容。

### Attribute and Structure Preserving Graph Contrastive Learning
> **自监督GCL**
 - [[paper](https://ojs.aaai.org/index.php/AAAI/article/view/25858/25630)]
 - [[code](https://github.com/JialuChenChina/ASP)]
 - 图形对比学习（GCL）具有很强的自我监督能力，能同时捕捉图形结构和节点属性信息，因此备受研究关注。目前的 GCL 方法通常采用图神经网络（GNN）作为基础编码器，这通常依赖于网络的同质性假设，忽略了属性空间中节点的相似性。在很多情况下，这种假设无法满足，或者节点相似性起着至关重要的作用。为了设计一种更稳健的机制，我们开发了一种新颖的属性和结构保存图对比学习框架，命名为 ASP，它在利用图结构的同时，全面有效地保存了节点属性。具体来说，我们的框架考虑了三种不同的图视图，即原始视图、属性视图和全局结构视图。然后，我们以联合的方式对三种视图进行对比学习，从而挖掘出全面的图信息。我们在具有不同同亲程度的各种真实世界网络上验证了所提框架的有效性。结果表明，我们的模型性能优于具有代表性的基线模型。

### Neighbor Contrastive Learning on Learnable Graph Augmentation
> **自监督GCL**
 - [[paper](https://ojs.aaai.org/index.php/AAAI/article/view/26168/25940)]
 - [[code](https://github.com/shenxiaocam/NCLA)]
 - 近年来，旨在从无标签图中学习表征的图对比学习（GCL）取得了长足的进步。然而，现有的 GCL 方法大多采用人为设计的图增强，这对各种图数据集都很敏感。此外，最初在计算机视觉中开发的对比损失被直接应用到图数据中，相邻节点被视为负节点，因此被推离锚点很远。然而，这与网络的同类假设是矛盾的，同类假设认为连接的节点通常属于同一类别，应该彼此靠近。在这项工作中，我们提出了一种端到端自动 GCL 方法，命名为 NCLA，将邻接对比学习应用于可学习的图增强。通过多头图关注机制自动学习多个具有自适应拓扑结构的图增强视图，该方法可与各种图数据集兼容，而无需先验的领域知识。此外，通过将网络拓扑结构作为监督信号，还设计了一种邻接对比损失，允许每个锚出现多个阳性结果。在所提出的 NCLA 中，增强和嵌入都是端到端学习的。在基准数据集上进行的大量实验表明，NCLA 在自监督 GCL 上的节点分类性能达到了最先进的水平，甚至在标签极其有限的情况下超过了监督分类。

### Eliciting Structural and Semantic Global Knowledge in Unsupervised Graph Contrastive Learning
> **无监督GCL**
 - [[paper](https://ojs.aaai.org/index.php/AAAI/article/view/25898/25670)]
 - [[code](https://github.com/kaize0409/S-3-CL)]
 - 最近，图形对比学习（GCL）在以自我监督的方式学习可概括的节点表征方面引起了广泛的研究兴趣。一般来说，GCL 中的对比学习过程是在图神经网络（GNN）骨干学习到的表征基础上进行的，该骨干会根据节点的局部邻域转换和传播节点的上下文信息。然而，具有相似特征的节点不一定总是紧密相连，这给无监督 GCL 的工作带来了巨大挑战，因为它们在捕捉这种全局图知识方面存在固有的局限性。在这项工作中，我们提出了一个简单而有效的框架--具有结构和语义对比学习（S3-CL）的简单神经网络，从而解决了它们固有的局限性。值得注意的是，凭借所提出的结构和语义对比学习算法，即使是简单的神经网络也能学习到富有表现力的节点表示，从而保留有价值的全局结构和语义模式。我们的实验证明，与最先进的无监督 GCL 方法相比，S3-CL 学习到的节点表征在不同的下游任务中都取得了优异的性能。

### GENNAPE: Towards Generalized Neural Architecture Performance Estimators
 - [[paper](https://arxiv.org/pdf/2211.17226.pdf)]
 - [[code](https://github.com/Ascend-Research/GENNAPE)]
 - 预测神经架构性能是一项具有挑战性的任务，对于神经架构设计和搜索至关重要。现有的方法要么依赖于神经性能预测器，而这种预测器仅限于在涉及特定算子集和连接规则的预定义设计空间中对架构进行建模，无法泛化到未见过的架构；要么依赖于零成本代理，而这种代理并不总是准确的。在本文中，我们提出了通用神经架构性能估算器 GENNAPE，该估算器在开放的神经架构基准上进行了预训练，旨在通过对网络表示、对比预训练和基于模糊聚类的预测器集合的综合创新，推广到完全未见过的架构。具体来说，GENNAPE 将给定的神经网络表示为原子运算的计算图 (CG)，可以模拟任意架构。它首先通过对比学习（Contrastive Learning）学习图编码器，以鼓励通过拓扑特征进行网络分离，然后训练多个预测头，预测头根据神经网络的模糊成员资格进行软聚类。实验表明，在 NAS-Bench-101 上进行预训练的 GENNAPE 可以在不进行微调或微调最小化的情况下，在 5 种不同的公共神经网络基准（包括 NAS-Bench-201、NAS-Bench-301、MobileNet 和 ResNet 系列）上实现卓越的可移植性。我们还引入了 3 个具有挑战性的新标签神经网络基准：HiAML、Inception 和 Two-Path，它们可以集中在较窄的精度范围内。大量实验表明，GENNAPE 可以正确分辨出这些系列中的高性能架构。最后，当与搜索算法搭配使用时，GENNAPE 可以在三个系列中找到既能提高准确度又能减少 FLOP 的架构。

### Deep Graph Structural Infomax
> **自监督+细粒度**
 - [[paper](https://ojs.aaai.org/index.php/AAAI/article/view/25618/25390)]
 - 在自监督图学习领域，最近引入了互信息（MI）用于图编码，以生成稳健的节点嵌入。Deep Graph Infomax（DGI）是其中一个成功的代表，它本质上是在节点特征空间上运行，但忽略了拓扑结构，只考虑全局图摘要。在本文中，我们提出了一种有效的学习节点表征的模型，称为深度图结构 Infomax（DGSI）。我们从信息瓶颈（Information Bottleneck，IB）的角度探索结构互信息的推导，它定义了在拓扑结构保持的条件下表示的充分性和最小性之间的权衡。直观地说，衍生的约束条件在形式上最大化了边缘和局部邻域的结构互信息。此外，我们还开发了一个通用框架，将全局表征互信息、局部表征互信息和充分结构信息纳入节点表征中。从本质上讲，我们的 DGSI 是对 DGI 的扩展，能以自我监督的方式捕获更多细粒度的语义信息和有益的结构信息，从而改进节点表示，进一步提高学习性能。在不同类型数据集上的广泛实验证明了所提方法的有效性和优越性。

### Spectral Feature Augmentation for Graph Contrastive Learning and Beyond
 - [[paper](https://arxiv.org/pdf/2212.01026.pdf)]
 - [[code]()]



## General Contrastive Learning
 - [CMNet: Contrastive Magnification Network for Micro-Expression Recognition](https://ojs.aaai.org/index.php/AAAI/article/view/25083)
 - [Self-Contrastive Learning: Single-Viewed Supervised Contrastive Framework Using Sub-network](https://ojs.aaai.org/index.php/AAAI/article/view/25091)
 - [Cross-Modal Label Contrastive Learning for Unsupervised Audio-Visual Event Localization](https://ojs.aaai.org/index.php/AAAI/article/view/25093)
 - [DUET: Cross-Modal Semantic Grounding for Contrastive Zero-Shot Learning](https://ojs.aaai.org/index.php/AAAI/article/view/25114)
 - [Cross-Modality Person Re-identification with Memory-Based Contrastive Embedding](https://ojs.aaai.org/index.php/AAAI/article/view/25116)
 - [Hierarchical Contrast for Unsupervised Skeleton-Based Action Representation Learning](https://ojs.aaai.org/index.php/AAAI/article/view/25127)
 - [TaCo: Textual Attribute Recognition via Contrastive Learning](https://ojs.aaai.org/index.php/AAAI/article/view/25286)
 - [Find Beauty in the Rare: Contrastive Composition Feature Clustering for Nontrivial Cropping Box Regression](https://ojs.aaai.org/index.php/AAAI/article/view/25293)
 - [Mean-Shifted Contrastive Loss for Anomaly Detection](https://ojs.aaai.org/index.php/AAAI/article/view/25309)
 - [UCoL: Unsupervised Learning of Discriminative Facial Representations via Uncertainty-Aware Contrast](https://ojs.aaai.org/index.php/AAAI/article/view/25348)
 - [Contrastive Masked Autoencoders for Self-Supervised Video Hashing](https://ojs.aaai.org/index.php/AAAI/article/view/25373)
 - [Cross-Modal Contrastive Learning for Domain Adaptation in 3D Semantic Segmentation](https://ojs.aaai.org/index.php/AAAI/article/view/25400)
 - [Inter-image Contrastive Consistency for Multi-Person Pose Estimation](https://ojs.aaai.org/index.php/AAAI/article/view/25410)
 - [Contrastive Multi-Task Dense Prediction](https://ojs.aaai.org/index.php/AAAI/article/view/25424)
 - [Hierarchical Consistent Contrastive Learning for Skeleton-Based Action Recognition with Growing Augmentations](https://ojs.aaai.org/index.php/AAAI/article/view/25451)
 - [Memory-Aided Contrastive Consensus Learning for Co-salient Object Detection](https://ojs.aaai.org/index.php/AAAI/article/view/25480)
 - [Generative Image Inpainting with Segmentation Confusion Adversarial Training and Contrastive Learning](https://ojs.aaai.org/index.php/AAAI/article/view/25502)
 - [Contrastive Pre-training with Adversarial Perturbations for Check-In Sequence Representation Learning](https://ojs.aaai.org/index.php/AAAI/article/view/25546)
 - [MA-GCL: Model Augmentation Tricks for Graph Contrastive Learning](https://ojs.aaai.org/index.php/AAAI/article/view/25547)
 - [Time Series Contrastive Learning with Information-Aware Augmentations](https://ojs.aaai.org/index.php/AAAI/article/view/25575)
 - [Cross-Domain Graph Anomaly Detection via Anomaly-Aware Contrastive Alignment](https://ojs.aaai.org/index.php/AAAI/article/view/25591)
 - [Contrastive Classification and Representation Learning with Probabilistic Interpretation](https://ojs.aaai.org/index.php/AAAI/article/view/25819)
 - [Attribute and Structure Preserving Graph Contrastive Learning](https://ojs.aaai.org/index.php/AAAI/article/view/25858)
 - [Supervised Contrastive Few-Shot Learning for High-Frequency Time Series](https://ojs.aaai.org/index.php/AAAI/article/view/25863)
 - [Contrastive Learning with the Feature Reconstruction Amplifier](https://ojs.aaai.org/index.php/AAAI/article/view/25887)
 - [Graph Anomaly Detection via Multi-Scale Contrastive Learning Networks with Augmented View](https://ojs.aaai.org/index.php/AAAI/article/view/25907)
 - [Audio-Visual Contrastive Learning with Temporal Self-Supervision](https://ojs.aaai.org/index.php/AAAI/article/view/25967)
 - [DICNet: Deep Instance-Level Contrastive Network for Double Incomplete Multi-View Multi-Label Classification](https://ojs.aaai.org/index.php/AAAI/article/view/26059)
 - [Hard Sample Aware Network for Contrastive Deep Graph Clustering](https://ojs.aaai.org/index.php/AAAI/article/view/26071)
 - [MHCCL: Masked Hierarchical Cluster-Wise Contrastive Learning for Multivariate Time Series](https://ojs.aaai.org/index.php/AAAI/article/view/26098)
 - [Neighbor Contrastive Learning on Learnable Graph Augmentation](https://ojs.aaai.org/index.php/AAAI/article/view/26168)
 - [Hierarchical Contrastive Learning for Temporal Point Processes](https://ojs.aaai.org/index.php/AAAI/article/view/26211)
 - [Generalized Semantic Segmentation by Self-Supervised Source Domain Projection and Multi-Level Contrastive Learning](https://ojs.aaai.org/index.php/AAAI/article/view/26280)
 - [Cluster-Guided Contrastive Graph Clustering Network](https://ojs.aaai.org/index.php/AAAI/article/view/26285)
 - [ImGCL: Revisiting Graph Contrastive Learning on Imbalanced Node Classification](https://ojs.aaai.org/index.php/AAAI/article/view/26319)
 - [Spectral Feature Augmentation for Graph Contrastive Learning and Beyond](https://ojs.aaai.org/index.php/AAAI/article/view/26336)

## Weakly-supervised Learning
 - [MGFN: Magnitude-Contrastive Glance-and-Focus Network for Weakly-Supervised Video Anomaly Detection](https://ojs.aaai.org/index.php/AAAI/article/view/25112)
 - [Weakly-Supervised Semantic Segmentation for Histopathology Images Based on Dataset Synthesis and Feature Consistency Constraint](https://ojs.aaai.org/index.php/AAAI/article/view/25136)
 - [Point-Teaching: Weakly Semi-supervised Object Detection with Point Annotations](https://ojs.aaai.org/index.php/AAAI/article/view/25143)
 - [Weakly-Supervised Camouflaged Object Detection with Scribble Annotations](https://ojs.aaai.org/index.php/AAAI/article/view/25156)
 - [Weakly-Guided Self-Supervised Pretraining for Temporal Activity Detection](https://ojs.aaai.org/index.php/AAAI/article/view/25189)
 - [Semantic-Aware Superpixel for Weakly Supervised Semantic Segmentation](https://ojs.aaai.org/index.php/AAAI/article/view/25196)
 - [Weakly Supervised 3D Segmentation via Receptive-Driven Pseudo Label Consistency and Structural Consistency](https://ojs.aaai.org/index.php/AAAI/article/view/25205)
 - [Actionness Inconsistency-Guided Contrastive Learning for Weakly-Supervised Temporal Action Localization](https://ojs.aaai.org/index.php/AAAI/article/view/25237)
 - [Coarse2Fine: Local Consistency Aware Re-prediction for Weakly Supervised Object Localization](https://ojs.aaai.org/index.php/AAAI/article/view/25292)
 - [Dual Memory Units with Uncertainty Regulation for Weakly Supervised Video Anomaly Detection](https://ojs.aaai.org/index.php/AAAI/article/view/25489)
 - [Frame-Level Label Refinement for Skeleton-Based Weakly-Supervised Action Recognition](https://ojs.aaai.org/index.php/AAAI/article/view/25439)
 - [Self Correspondence Distillation for End-to-End Weakly-Supervised Semantic Segmentation](https://ojs.aaai.org/index.php/AAAI/article/view/25408)
 - [Background-Mixed Augmentation for Weakly Supervised Change Detection](https://ojs.aaai.org/index.php/AAAI/article/view/25958)
 - [Losses over Labels: Weakly Supervised Learning via Direct Loss Construction](https://ojs.aaai.org/index.php/AAAI/article/view/26159)

## Label Noise Learning
 - [Denoising after Entropy-Based Debiasing a Robust Training Method for Dataset Bias with Noisy Labels](https://ojs.aaai.org/index.php/AAAI/article/view/25205)
 - [Truncate-Split-Contrast: A Framework for Learning from Mislabeled Videos](https://ojs.aaai.org/index.php/AAAI/article/view/25375)
 - [Class-Independent Regularization for Learning with Noisy Labels](https://ojs.aaai.org/index.php/AAAI/article/view/25434)
 - [ADMoE: Anomaly Detection with Mixture-of-Experts from Noisy Labels](https://ojs.aaai.org/index.php/AAAI/article/view/25620)
 - [Learning from Training Dynamics: Identifying Mislabeled Data beyond Manually Designed Features](https://ojs.aaai.org/index.php/AAAI/article/view/25972)
 - [A Gift from Label Smoothing: Robust Training with Adaptive Label Smoothing via Auxiliary Classifier under Label Noise](https://ojs.aaai.org/index.php/AAAI/article/view/26004)


 - [USDNL: Uncertainty-Based Single Dropout in Noisy Label Learning](https://ojs.aaai.org/index.php/AAAI/article/view/26264)
 - [STARS: Spatial-Temporal Active Re-sampling for Label-Efficient Learning from Noisy Annotations](https://ojs.aaai.org/index.php/AAAI/article/view/26301)
 - [Two Wrongs Don’t Make a Right: Combating Confirmation Bias in Learning with Label Noise](https://ojs.aaai.org/index.php/AAAI/article/view/26725)
 - [Rethinking Label Refurbishment: Model Robustness under Label Noise](https://ojs.aaai.org/index.php/AAAI/article/view/26751)
